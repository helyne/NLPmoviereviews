{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis with NLTK Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Naive Bayes classifier determines the probability that an input text belongs to one of a set of classes, eg. predicting if a review is positive or negative.\n",
    "\n",
    "It is ‘Naive’ because it assumes the words in the text are independent (even though in reality, in natural human language, the order of words convey contextual information).  Despite these assumptions, Naive Bayes has a high degree of accuracy when predicting classes with only a small training set.\n",
    "\n",
    "- Zhang, H. (2004). The optimality of naive Bayes. Aa, 1(2), 3. https://www.aaai.org/Papers/FLAIRS/2004/Flairs04-097.pdf\n",
    "- Baines, O., Naive Bayes: Machine Learning and Text Classification Application of Bayes’ Theorem. https://journals.le.ac.uk/ojs1/index.php/lumj/article/download/3484/3110"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics.scores import precision, recall, f_measure\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "from NLPmoviereviews.data import load_data_sent\n",
    "from NLPmoviereviews.utilities import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train, y_train, X_test, y_test = load_data_sent(percentage_of_sentences=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove custom stop-words\n",
    "def rm_custom_stops(sentence):\n",
    "    '''\n",
    "    Custom stop word remover\n",
    "    Parameters:\n",
    "        sentence (str): a string of words\n",
    "    Returns:\n",
    "        list_of_words (list): cleaned sentence as a list of words\n",
    "    '''\n",
    "    words = sentence.split()\n",
    "    stop_words = {'movie', 'film', 'br', 'x96'}\n",
    "    \n",
    "    return [w for w in words if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform preprocessing (cleaning) & transform to dataframe\n",
    "def process_df(X, y):\n",
    "    '''\n",
    "    Transform texts and labels into dataframe of \n",
    "    cleaned texts (as list of words) and human readable target labels\n",
    "    \n",
    "    Parameters:\n",
    "        X (list): list of strings (reviews)\n",
    "        y (list): list of target labels (0/1)\n",
    "    Returns:\n",
    "        df (dataframe): dataframe of processed reviews (as list of words)\n",
    "                        and corresponding sentiment label (positive/negative)\n",
    "    '''\n",
    "    # create dataframe from data\n",
    "    d = {'text': X, 'sentiment': y}\n",
    "    df = pd.DataFrame(d)\n",
    "    \n",
    "    # make sentiment human-readable\n",
    "    df['sentiment'] = df.sentiment.map(lambda x: 'positive' if x==1 else 'negative')\n",
    "\n",
    "    # clean and split text into list of words\n",
    "    df['text'] = df.text.apply(preprocessing)\n",
    "    df['text'] = df.text.apply(rm_custom_stops)\n",
    "\n",
    "    # Generate the feature sets for the movie review documents one by one\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data\n",
    "train_df = process_df(X_train, y_train)\n",
    "test_df = process_df(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[absolutely, terrible, dont, lure, christopher...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[know, fall, asleep, usually, due, combination...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mann, photograph, alberta, rocky, mountain, s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[kind, snowy, sunday, afternoon, rest, world, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[others, mention, woman, go, nude, mostly, abs...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  [absolutely, terrible, dont, lure, christopher...  negative\n",
       "1  [know, fall, asleep, usually, due, combination...  negative\n",
       "2  [mann, photograph, alberta, rocky, mountain, s...  negative\n",
       "3  [kind, snowy, sunday, afternoon, rest, world, ...  positive\n",
       "4  [others, mention, woman, go, nude, mostly, abs...  positive"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect dataframe\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create list of most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency distribution of words in corpus & select 2000 most common words\n",
    "def most_common(df, n=2000):\n",
    "    '''\n",
    "    Get n most common words from data frame of text reviews\n",
    "    \n",
    "    Parameters:\n",
    "        df (dataframe): dataframe with column of processed text reviews\n",
    "        n (int): number of most common words to get\n",
    "    Returns:\n",
    "        most_common_words (list): list of n most common words\n",
    "    '''\n",
    "    # create list of all words in the train data\n",
    "    complete_corpus = df.text.sum()\n",
    "    \n",
    "    # Construct a frequency dict of all words in the overall corpus \n",
    "    all_words = nltk.FreqDist(w.lower() for w in complete_corpus)\n",
    "\n",
    "    # select the 2,000 most frequent words (incl. frequency)\n",
    "    most_common_words = all_words.most_common(n)\n",
    "    \n",
    "    return [item[0] for item in most_common_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'make',\n",
       " 'like',\n",
       " 'see',\n",
       " 'get',\n",
       " 'time',\n",
       " 'good',\n",
       " 'go',\n",
       " 'watch',\n",
       " 'character']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 2000 most common words\n",
    "most_common_2000 = most_common(train_df)\n",
    "\n",
    "# inspect first 10 most common words\n",
    "most_common_2000[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create nltk featuresets from train/test\n",
    "\n",
    "For the nltk naive bayes classifier, we must tokenize the sentence and figure out which words the sentence shares with all_words/most_common_words. These constitute the sentence's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given text, create a featureset (dict of features - {'word': True/False})\n",
    "def review_features(review, most_common_words):\n",
    "    '''\n",
    "    Feature extractor that checks whether each of the most\n",
    "    common words is present in a given review\n",
    "    \n",
    "    Parameters:\n",
    "        review (list): text reviews as list of words\n",
    "        most_common_words (list): list of n most common words\n",
    "    Returns:\n",
    "        features (dict): dict of most common words & corresponding True/False\n",
    "    '''\n",
    "    review_words = set(review)\n",
    "    features = {}\n",
    "    for word in most_common_words:\n",
    "        features['contains(%s)' % word] = (word in review_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create featureset for each text in a given dataframe\n",
    "def make_set(df, most_common_words):\n",
    "    '''\n",
    "    Generates nltk featuresets for each movie review in dataframe.\n",
    "    Feature sets are composed of a dict describing whether each of the most \n",
    "    common words is present in the text review or not\n",
    "\n",
    "    Parameters:\n",
    "        df (dataframe): processed dataframe of text reviews\n",
    "        most_common_words (list): list of most common words\n",
    "    Returns:\n",
    "        feature_set (list): list of dicts of most common words & corresponding True/False\n",
    "    '''\n",
    "    return [(review_features(df.text[i], most_common_words), df.sentiment[i]) for i in range(len(df.sentiment))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data into featuresets (for nltk naive bayes classifier)\n",
    "train_set = make_set(train_df, most_common_2000)\n",
    "test_set = make_set(test_df, most_common_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('contains(one)', False),\n",
       "  ('contains(make)', True),\n",
       "  ('contains(like)', True),\n",
       "  ('contains(see)', False),\n",
       "  ('contains(get)', False),\n",
       "  ('contains(time)', False),\n",
       "  ('contains(good)', True),\n",
       "  ('contains(go)', False),\n",
       "  ('contains(watch)', False),\n",
       "  ('contains(character)', False)],\n",
       " 'negative')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect first train featureset\n",
    "first_label = train_set[0][1]\n",
    "first_featureset_first10 = list(train_set[0][0].items())[:10]\n",
    "first_featureset_first10, first_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train & evaluate model (naive bayes classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a naive bayes classifier with train set by nltk\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the accuracy of the naive bayes classifier with test set\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build reference and test set of observed values (for each label)\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    " \n",
    "for i, (feats, label) in enumerate(train_set):\n",
    "    refsets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    testsets[observed].add(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos precision: 0.8739232576350823\n",
      "pos recall: 0.9036437246963562\n",
      "pos F-measure: 0.8885350318471338\n",
      "neg precision: 0.902698282910875\n",
      "neg recall: 0.8727272727272727\n",
      "neg F-measure: 0.8874598070739551\n"
     ]
    }
   ],
   "source": [
    "# print precision, recall, and f-measure\n",
    "print('pos precision:', precision(refsets['positive'], testsets['positive']))\n",
    "print('pos recall:', recall(refsets['positive'], testsets['positive']))\n",
    "print('pos F-measure:', f_measure(refsets['positive'], testsets['positive']))\n",
    "print('neg precision:', precision(refsets['negative'], testsets['negative']))\n",
    "print('neg recall:', recall(refsets['negative'], testsets['negative']))\n",
    "print('neg F-measure:', f_measure(refsets['negative'], testsets['negative']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "     contains(underrate) = True           positi : negati =     16.7 : 1.0\n",
      "    contains(ridiculous) = True           negati : positi =     16.4 : 1.0\n",
      "       contains(unfunny) = True           negati : positi =     13.3 : 1.0\n",
      "        contains(unfold) = True           positi : negati =      9.6 : 1.0\n",
      "   contains(wonderfully) = True           positi : negati =      8.6 : 1.0\n",
      "         contains(appal) = True           negati : positi =      8.4 : 1.0\n",
      "          contains(lame) = True           negati : positi =      8.0 : 1.0\n",
      "          contains(dumb) = True           negati : positi =      7.9 : 1.0\n",
      "         contains(awful) = True           negati : positi =      7.8 : 1.0\n",
      "         contains(waste) = True           negati : positi =      7.3 : 1.0\n",
      "     contains(laughable) = True           negati : positi =      7.3 : 1.0\n",
      "         contains(worst) = True           negati : positi =      7.2 : 1.0\n",
      "       contains(rubbish) = True           negati : positi =      7.1 : 1.0\n",
      "         contains(ninja) = True           negati : positi =      6.8 : 1.0\n",
      "     contains(pointless) = True           negati : positi =      6.8 : 1.0\n",
      "        contains(redeem) = True           negati : positi =      6.8 : 1.0\n",
      "   contains(magnificent) = True           positi : negati =      6.6 : 1.0\n",
      "        contains(giallo) = True           positi : negati =      6.5 : 1.0\n",
      "        contains(asleep) = True           negati : positi =      6.3 : 1.0\n",
      "        contains(subtle) = True           positi : negati =      6.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# show top n most informative features\n",
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that people who give a positive review of a film are more likely to use words such as \"underrate\", \"unfold\", \"wonderfully\", or \"subtle\", while people who give a negative review are more likely to use words such as \"ridiculous\", \"unfunny\", \"waste\", or \"asleep\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on new review (from mubi.com)\n",
    "new_review = \"Surprisingly effective and moving, The Balcony Movie takes the Front Up\\\n",
    "            concept of talking to strangers, but here attaches it to a fixed perspective \\\n",
    "            in order to create a strong sense of the stream of life passing us by. \\\n",
    "            It's possible to not only witness the subtle changing of seasons\\\n",
    "            but also the gradual opening of trust and confidence in Lozinski's \\\n",
    "            repeating characters. A Pandemic movie, pre-pandemic. 3.5 stars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform preprocessing (cleaning & featureset transformation)\n",
    "processed_review = rm_custom_stops(preprocessing(new_review))\n",
    "processed_review = review_features(processed_review, most_common_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict label\n",
    "classifier.classify(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       negative\n",
      "0    contains(underrate): 0.12%\n",
      "1   contains(ridiculous): 5.96%\n",
      "2      contains(unfunny): 1.62%\n",
      "3       contains(unfold): 0.20%\n",
      "4  contains(wonderfully): 0.28%\n",
      "5        contains(appal): 1.70%\n",
      "6         contains(lame): 5.49%\n",
      "7         contains(dumb): 3.52%\n",
      "8       contains(awful): 10.39%\n",
      "9       contains(waste): 12.68%\n",
      "                       positive\n",
      "0    contains(underrate): 1.98%\n",
      "1   contains(ridiculous): 0.36%\n",
      "2      contains(unfunny): 0.12%\n",
      "3       contains(unfold): 1.90%\n",
      "4  contains(wonderfully): 2.39%\n",
      "5        contains(appal): 0.20%\n",
      "6         contains(lame): 0.69%\n",
      "7         contains(dumb): 0.44%\n",
      "8        contains(awful): 1.33%\n",
      "9        contains(waste): 1.74%\n"
     ]
    }
   ],
   "source": [
    "# to get individual probability for each label and word, taken from:\n",
    "# https://stackoverflow.com/questions/20773200/python-nltk-naive-bayes-probabilities\n",
    "\n",
    "# show individual probabilities for top 10 most informative words\n",
    "for label in classifier.labels():\n",
    "    indv_probs = []\n",
    "    for (word, fval) in classifier.most_informative_features(10):\n",
    "        _prob = \"{0:.2f}%\".format(100*classifier._feature_probdist[label, word].prob(fval))\n",
    "        indv_probs.append(f\"{word}: {_prob}\")\n",
    "    print(pd.DataFrame({label: indv_probs}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('nlpreviews')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecbb573cc41fe6baf34354607df718ebf4ab136e8601a96e7a6da1a1db011e8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
